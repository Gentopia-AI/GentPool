{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datasets preprocess\n",
    "Process various types of datasets into a unified format, sample and store them, and add corresponding tags. \n",
    "\n",
    "Format:\n",
    "QA questions\n",
    "```json\n",
    "{\n",
    "    \"problem\": \"xxx\",\n",
    "    \"solution\": \"xxx\",\n",
    "    \"tags\": [\n",
    "        \"xxx/xxx\"\n",
    "    ]\n",
    "}\n",
    "```\n",
    "instruction following\n",
    "```json\n",
    "{\n",
    "    \"prompt\": \"xxx\",\n",
    "    \"eval_instruction\": \"xxx\",\n",
    "    \"tags\": [\n",
    "        \"xxx/xxx\"\n",
    "    ]\n",
    "}\n",
    "```\n",
    "coding\n",
    "```json\n",
    "{\n",
    "    \"problem\": \"xxx\",\n",
    "    \"test_case\": \"xxx\",\n",
    "    \"dataset\": \"xxx\",\n",
    "    \"tags\": [\n",
    "        \"xxx/xxx\"\n",
    "    ]\n",
    "}\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import random\n",
    "import csv\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recursive function to load json files from a path and its subdirectories\n",
    "def load_from_json_recursive(path):\n",
    "    data = []\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for file in files:\n",
    "            if file.endswith(\".json\"):\n",
    "                with open(os.path.join(root, file), 'r') as f:\n",
    "                    data.append(json.load(f))\n",
    "    return data\n",
    "\n",
    "def load_from_jsonl(file_path):\n",
    "    data = []\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            data.append(json.loads(line))\n",
    "    return data\n",
    "\n",
    "\n",
    "def load_from_csv_recursive(path):\n",
    "    data = []\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for file in files:\n",
    "            if file.endswith(\".csv\"):\n",
    "                with open(os.path.join(root, file), 'r') as f:\n",
    "                    csv_reader = csv.reader(f)\n",
    "                    for row in csv_reader:\n",
    "                        data.append(row)\n",
    "    return data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reasoning"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Math"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = 100\n",
    "output_dir = '../benchmark/public/reasoning/math'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "data_dir = '../benchmark/raw/MATH'\n",
    "tags = [\"reasoning/math\"]\n",
    "# Read MATH dataset\n",
    "data = load_from_json_recursive(data_dir)\n",
    "# Initial filter by level of difficulty\n",
    "hard_data = []\n",
    "for data_item in data:\n",
    "    if data_item[\"level\"] in [\"Level 5\"]:\n",
    "        hard_data.append(data_item)\n",
    "\n",
    "sampled_data = random.sample(hard_data, sample_size)\n",
    "\n",
    "for i, item in enumerate(sampled_data):\n",
    "    formatted_data = {\n",
    "        \"problem\": item[\"problem\"],\n",
    "        \"solution\": item[\"solution\"],\n",
    "        \"tags\": tags\n",
    "    }\n",
    "    \n",
    "    file_name = f'math_{i}.json'\n",
    "    \n",
    "    output_path = os.path.join(output_dir, file_name)\n",
    "    with open(output_path, 'w', encoding='utf-8') as outfile:\n",
    "        json.dump(formatted_data, outfile, indent=4, ensure_ascii=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GSM8K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = 50\n",
    "output_dir = '../benchmark/public/reasoning/math'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "data_dir = '../benchmark/raw/GSM8K'\n",
    "tags = [\"reasoning/math\"]\n",
    "\n",
    "test_data = load_from_jsonl(os.path.join(data_dir, 'test.jsonl'))\n",
    "train_data = load_from_jsonl(os.path.join(data_dir, 'train.jsonl'))\n",
    "\n",
    "combined_data = test_data + train_data\n",
    "\n",
    "sampled_data = random.sample(combined_data, sample_size)\n",
    "\n",
    "for i, item in enumerate(sampled_data):\n",
    "    formatted_data = {\n",
    "        \"problem\": item[\"question\"],\n",
    "        \"solution\": item[\"answer\"],\n",
    "        \"tags\": tags\n",
    "    }\n",
    "    \n",
    "    file_name = f'gsm8k_{i}.json'\n",
    "    \n",
    "    output_path = os.path.join(output_dir, file_name)\n",
    "    with open(output_path, 'w', encoding='utf-8') as outfile:\n",
    "        json.dump(formatted_data, outfile, indent=4, ensure_ascii=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coding"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HumanEval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = 50\n",
    "output_dir = '../benchmark/public/reasoning/coding'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "data_dir = '../benchmark/raw/HumanEval'\n",
    "tags = [\"reasoning/coding\"]\n",
    "\n",
    "data = load_from_jsonl(os.path.join(data_dir, 'human-eval-v2-20210705.jsonl'))\n",
    "\n",
    "sampled_data = random.sample(data, sample_size)\n",
    "\n",
    "for i, item in enumerate(sampled_data):\n",
    "    entry_point = item[\"entry_point\"]\n",
    "\n",
    "    ground_truth = item[\"prompt\"] + \"\\n\" + item[\"canonical_solution\"] + \"\\n\"\n",
    "    formatted_data = {\n",
    "        \"problem\": item['prompt'],\n",
    "        \"test_case\": item[\"test\"] + \"\\n\" + f\"check({item['entry_point']})\",\n",
    "        \"dataset\": \"humaneval\",\n",
    "        \"tags\": tags\n",
    "    }\n",
    "    \n",
    "    file_name = f'humaneval_{i}.json'\n",
    "    \n",
    "    output_path = os.path.join(output_dir, file_name)\n",
    "    with open(output_path, 'w', encoding='utf-8') as outfile:\n",
    "        json.dump(formatted_data, outfile, indent=4, ensure_ascii=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MBPP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = 50\n",
    "output_dir = '../benchmark/public/reasoning/coding'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "data_dir = '../benchmark/raw/MBPP'\n",
    "tags = [\"reasoning/coding\"]\n",
    "\n",
    "data = load_from_jsonl(os.path.join(data_dir, 'mbpp.jsonl'))\n",
    "\n",
    "sampled_data = random.sample(data, sample_size)\n",
    "\n",
    "for i, item in enumerate(sampled_data):\n",
    "    test_code = '\\n'.join(item[\"test_list\"])\n",
    "\n",
    "    input_data = f\"{item['text']}\\n\\nYour code should pass these tests:\\n\\n{test_code}\\n\\n\"\n",
    "    \n",
    "    ground_truth = item[\"code\"] \n",
    "    formatted_data = {\n",
    "        \"problem\": input_data,\n",
    "        \"test_case\": test_code,\n",
    "        \"dataset\": \"mbpp\",\n",
    "        \"tags\": tags\n",
    "    }\n",
    "    \n",
    "    file_name = f'mbpp_{i}.json'\n",
    "    \n",
    "    output_path = os.path.join(output_dir, file_name)\n",
    "    with open(output_path, 'w', encoding='utf-8') as outfile:\n",
    "        json.dump(formatted_data, outfile, indent=4, ensure_ascii=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "APPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = 100\n",
    "output_dir = '../benchmark/public/reasoning/coding'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "data_dir = '../benchmark/raw/APPS'\n",
    "tags = [\"reasoning/coding\"]\n",
    "\n",
    "data = load_from_jsonl(os.path.join(data_dir, 'test.jsonl'))\n",
    "hard_data = []\n",
    "for data_item in data:\n",
    "    if data_item[\"difficulty\"] in [\"competition\"]: # introductory, interview and competition\n",
    "        hard_data.append(data_item)\n",
    "\n",
    "sampled_data = random.sample(hard_data, sample_size)\n",
    "\n",
    "for i, item in enumerate(sampled_data):\n",
    "    \n",
    "    formatted_data = {\n",
    "        \"problem\": item[\"question\"],\n",
    "        \"test_case\": item[\"input_output\"],\n",
    "        \"dataset\": \"apps\",\n",
    "        \"tags\": tags\n",
    "    }\n",
    "    \n",
    "    file_name = f'apps_{i}.json'\n",
    "    \n",
    "    output_path = os.path.join(output_dir, file_name)\n",
    "    with open(output_path, 'w', encoding='utf-8') as outfile:\n",
    "        json.dump(formatted_data, outfile, indent=4, ensure_ascii=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Planning"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LLM-Plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = 100\n",
    "output_dir = '../benchmark/public/reasoning/planning'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "data_dir = '../benchmark/raw/LLM-Plan'\n",
    "tags = [\"reasoning/planning\"]\n",
    "\n",
    "instances = load_from_json_recursive(data_dir)\n",
    "data = []\n",
    "\n",
    "for item in instances:\n",
    "    for instance in item[\"instances\"]:\n",
    "        data.append(instance)\n",
    "\n",
    "\n",
    "sampled_data = random.sample(data, sample_size)\n",
    "\n",
    "for i, item in enumerate(sampled_data):\n",
    "    formatted_data = {\n",
    "        \"problem\": item[\"query\"],\n",
    "        \"solution\": item[\"ground_truth_plan\"],\n",
    "        \"tags\": tags\n",
    "    }\n",
    "    \n",
    "    file_name = f'planning_{i}.json'\n",
    "    \n",
    "    output_path = os.path.join(output_dir, file_name)\n",
    "    with open(output_path, 'w', encoding='utf-8') as outfile:\n",
    "        json.dump(formatted_data, outfile, indent=4, ensure_ascii=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Commonsense"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BBH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = 100\n",
    "output_dir = '../benchmark/public/reasoning/commonsense'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "data_dir = '../benchmark/raw/BBH'\n",
    "tags = [\"reasoning/commonsense\"]\n",
    "\n",
    "examples = load_from_json_recursive(data_dir)\n",
    "data = []\n",
    "\n",
    "for item in examples:\n",
    "    for instance in item[\"examples\"]:\n",
    "        data.append(instance)\n",
    "\n",
    "\n",
    "sampled_data = random.sample(data, sample_size)\n",
    "\n",
    "for i, item in enumerate(sampled_data):\n",
    "    formatted_data = {\n",
    "        \"problem\": item[\"input\"],\n",
    "        \"solution\": item[\"target\"],\n",
    "        \"tags\": tags\n",
    "    }\n",
    "    \n",
    "    file_name = f'bbh_{i}.json'\n",
    "    \n",
    "    output_path = os.path.join(output_dir, file_name)\n",
    "    with open(output_path, 'w', encoding='utf-8') as outfile:\n",
    "        json.dump(formatted_data, outfile, indent=4, ensure_ascii=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Knowledge"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### World_Knowledge (Offline)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MMLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = 100\n",
    "output_dir = '../benchmark/public/knowledge/world_knowledge'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "data_dir = '../benchmark/raw/MMLU'\n",
    "tags = [\"knowledge/world_knowledge\"]\n",
    "\n",
    "data = load_from_csv_recursive(data_dir)\n",
    "\n",
    "sampled_data = random.sample(data, sample_size)\n",
    "\n",
    "for i, item in enumerate(sampled_data):\n",
    "    if len(item) >= 6:\n",
    "        question = item[0]\n",
    "        choices = ['A. ' + item[1], 'B. ' + item[2], 'C. ' + item[3], 'D. ' + item[4]]\n",
    "        answer = item[5]\n",
    "        input_str = question + \"\\n\" + \"\\n\".join(choices) + \"\\nAmong A through D, the answer is\"\n",
    "        formatted_data = {\n",
    "            \"problem\": input_str,\n",
    "            \"solution\": answer,\n",
    "            \"tags\": tags\n",
    "        }\n",
    "    \n",
    "        file_name = f'mmlu_{i}.json'\n",
    "        \n",
    "        output_path = os.path.join(output_dir, file_name)\n",
    "        with open(output_path, 'w', encoding='utf-8') as outfile:\n",
    "            json.dump(formatted_data, outfile, indent=4, ensure_ascii=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Domain_Specific_Knowledge (Offline)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AGIEval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = 100\n",
    "output_dir = '../benchmark/public/knowledge/domain_specific_knowledge'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "data_dir = '../benchmark/raw/AGIEval'\n",
    "tags = [\"knowledge/domain_specific_knowledge\"]\n",
    "\n",
    "english_qa_datasets = [\"lsat-ar\", \"lsat-lr\", \"lsat-rc\", \"logiqa-en\", \"sat-math\", \"sat-en\", \"aqua-rat\", \"sat-en-without-passage\", \"gaokao-english\"]\n",
    "chinese_qa_datasets = [\"logiqa-zh\", \"jec-qa-kd\", \"jec-qa-ca\", \"gaokao-chinese\", \"gaokao-geography\", \"gaokao-history\", \"gaokao-biology\", \"gaokao-chemistry\", \"gaokao-physics\", \"gaokao-mathqa\"]\n",
    "english_cloze_datasets = [\"math\"]\n",
    "chinese_cloze_datasets = [\"gaokao-mathcloze\"]\n",
    "\n",
    "multi_choice_datasets = [\"jec-qa-kd\", \"jec-qa-ca\", \"gaokao-physics\"]\n",
    "math_output_datasets = {\"gaokao-mathcloze\", \"math\"}\n",
    "\n",
    "data = []\n",
    "\n",
    "for file in os.listdir(data_dir):\n",
    "    if file.endswith(\".jsonl\"):\n",
    "        filename, _ = os.path.splitext(file)\n",
    "        data_one = load_from_jsonl(os.path.join(data_dir, file))\n",
    "        for i, item in enumerate(data_one):\n",
    "            passage = item[\"passage\"] if item.get(\"passage\") is not None else \"\"\n",
    "            if filename in english_qa_datasets:\n",
    "                option_string = \"ABCDEFG\"\n",
    "                count = len(item.get(\"options\", []))\n",
    "                count = 5 if count == 1 else count\n",
    "                problem = passage + \"Q: \" + item[\"question\"] + \" \" + \"Answer Choices: \" + \" \".join(item.get(\"options\", [])) + \"\\n\" + \\\n",
    "                       \"A: Among A through {}, the answer is\".format(option_string[count - 1])\n",
    "                solution = item[\"label\"]\n",
    "\n",
    "            elif filename in chinese_qa_datasets:\n",
    "                option_string = \"ABCDEFG\"\n",
    "                count = len(item.get(\"options\", []))\n",
    "                count = 4 if count == 1 else count\n",
    "                problem = passage + \"问题：\" + item[\"question\"] + \" \" + \"选项：\" + \" \".join(item.get(\"options\", [])) + \"\\n\" + \\\n",
    "                       \"答案：从A到{}, 我们应选择\".format(option_string[count - 1])\n",
    "                solution = item[\"label\"]\n",
    "\n",
    "            elif filename in english_cloze_datasets:\n",
    "                problem = passage + \"Q: \" + item[\"question\"] + \"\\n\" \"A: The answer is\"\n",
    "                solution = item[\"answer\"]\n",
    "\n",
    "            elif filename in chinese_cloze_datasets:\n",
    "                problem = passage + \"问题：\" + item[\"question\"] + \"\\n\" \"答案：\"\n",
    "                solution = item[\"answer\"]\n",
    "            formatted_data = {\n",
    "                \"problem\": problem,\n",
    "                \"solution\": solution,\n",
    "                \"tags\": tags\n",
    "            }\n",
    "            data.append(formatted_data)\n",
    "\n",
    "sampled_data = random.sample(data, sample_size)\n",
    "for i, item in enumerate(sampled_data):\n",
    "    file_name = f'agieval_{i}.json'\n",
    "\n",
    "    output_path = os.path.join(output_dir, file_name)\n",
    "    with open(output_path, 'w', encoding='utf-8') as outfile:\n",
    "        json.dump(item, outfile, indent=4, ensure_ascii=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
